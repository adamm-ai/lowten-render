


from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import json
import logging
import asyncio
import os
import re
from datetime import datetime, timedelta
from functools import lru_cache
import hashlib
import time
from dataclasses import dataclass
import uuid

# Importation Groq pour Llama3 (recherche)
from groq import Groq

# Importation Anthropic pour Claude 4 Sonnet (conversation)
import anthropic

# Configuration des logs avec token tracking
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- CONFIGURATION ---

# Base de donnÃ©es PostgreSQL
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME")

# Elasticsearch
ES_INDEX = os.getenv("ES_INDEX")
ES_CLOUD_URL = os.getenv("ES_CLOUD_URL")
ES_API_KEY = os.getenv("ES_API_KEY")

# Configuration Groq (recherche LLaMA3)
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
os.environ["GROQ_API_KEY"] = GROQ_API_KEY
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama3-70b-8192")

# Configuration Anthropic (Claude)
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
CLAUDE_MODEL = os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-20240620")

# --- CONNEXIONS ---
from sqlalchemy import create_engine
from elasticsearch import Elasticsearch

logger.info("Initialisation des connexions...")
engine = create_engine(f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}")
es = Elasticsearch(ES_CLOUD_URL, api_key=ES_API_KEY)

# Initialisation des clients IA
groq_client = Groq(api_key=GROQ_API_KEY)
anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

# --- SYSTÃˆME DE TRACKING DES TOKENS AVANCÃ‰ ---
@dataclass
class TokenUsage:
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    cost_estimate: float
    model: str
    timestamp: datetime
    usage_type: str  # 'search', 'conversation', 'intent_analysis'

class AdvancedTokenTracker:
    """SystÃ¨me de tracking des tokens pour les deux APIs"""
    
    def __init__(self):
        self.daily_usage = []
        self.total_usage = {
            'total_tokens': 0,
            'total_queries': 0,
            'total_cost': 0.0,
            'search_tokens': 0,
            'conversation_tokens': 0,
            'intent_analysis_tokens': 0
        }
        
        # Prix par 1K tokens
        self.pricing = {
            'llama3-70b-8192': {'input': 0.001, 'output': 0.001},
            'claude-4-sonnet-20241022': {'input': 0.003, 'output': 0.015},
            'mixtral-8x7b-32768': {'input': 0.001, 'output': 0.001}
        }
    
    def log_usage(self, usage: TokenUsage):
        """Log l'utilisation des tokens avec dÃ©tails avancÃ©s"""
        self.daily_usage.append(usage)
        self.total_usage['total_tokens'] += usage.total_tokens
        self.total_usage['total_queries'] += 1
        self.total_usage['total_cost'] += usage.cost_estimate
        
        if usage.usage_type == 'search':
            self.total_usage['search_tokens'] += usage.total_tokens
        elif usage.usage_type == 'intent_analysis':
            self.total_usage['intent_analysis_tokens'] += usage.total_tokens
        else:
            self.total_usage['conversation_tokens'] += usage.total_tokens
        
        # Log dÃ©taillÃ© dans le terminal
        logger.info("=" * 70)
        logger.info(f"ðŸ” TOKEN USAGE TRACKING - {usage.usage_type.upper()}")
        logger.info("=" * 70)
        logger.info(f"ðŸ¤– Model: {usage.model}")
        logger.info(f"ðŸ“ Prompt tokens: {usage.prompt_tokens:,}")
        logger.info(f"ðŸ’¬ Completion tokens: {usage.completion_tokens:,}")
        logger.info(f"ðŸ”¢ Total tokens: {usage.total_tokens:,}")
        logger.info(f"ðŸ’° Cost estimate: ${usage.cost_estimate:.6f}")
        logger.info(f"ðŸ“Š Type: {usage.usage_type}")
        logger.info(f"â° Timestamp: {usage.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 70)
    
    def calculate_cost(self, model: str, prompt_tokens: int, completion_tokens: int) -> float:
        """Calcule le coÃ»t estimÃ©"""
        if model not in self.pricing:
            return 0.0
        
        pricing = self.pricing[model]
        input_cost = (prompt_tokens / 1000) * pricing['input']
        output_cost = (completion_tokens / 1000) * pricing['output']
        return input_cost + output_cost

# Instance globale du tracker
token_tracker = AdvancedTokenTracker()

# --- ANALYSEUR D'INTENT INTELLIGENT AVEC CLAUDE ---
class IntelligentIntentAnalyzer:
    """Analyseur d'intent utilisant Claude 4 Sonnet pour des dÃ©cisions ultra-intelligentes"""
    
    def __init__(self):
        self.client = anthropic_client
        self.model = CLAUDE_MODEL
    
    async def analyze_intent_and_decide(self, user_message: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """Analyse intelligente avec Claude pour dÃ©cider des actions Ã  entreprendre"""
        
        # Construire le contexte de conversation
        context = ""
        if conversation_history and len(conversation_history) > 0:
            context = "\n\nCONTEXTE DE CONVERSATION PRÃ‰CÃ‰DENTE:\n"
            for msg in conversation_history[-5:]:  # Derniers 5 messages
                role = "Client" if msg["role"] == "user" else "Youssef"
                context += f"{role}: {msg['content']}\n"
        
        prompt = f"""Tu es Youssef, expert immobilier au Maroc. Analyse ce message client et dÃ©cide de la stratÃ©gie optimale.

MESSAGE CLIENT: "{user_message}"{context}

Analyse et rÃ©ponds avec un JSON exact dans ce format:

{{
    "should_search": true/false,
    "search_urgency": "immediate/progressive/none",
    "client_qualification_level": "cold/warm/hot/ready_to_visit",
    "detected_criteria": {{
        "has_location": true/false,
        "has_budget": true/false,
        "has_property_type": true/false,
        "has_size_requirements": true/false,
        "timeline_mentioned": true/false
    }},
    "conversation_strategy": "search_and_present/qualify_more/provide_consultation/book_visit",
    "next_qualifying_questions": ["question1", "question2"],
    "commercial_intent": "information_seeking/serious_buyer/just_browsing/ready_to_buy"
}}

DÃ‰CISIONS DE RECHERCHE:
- should_search = true si: critÃ¨res spÃ©cifiques mentionnÃ©s OU client semble prÃªt
- should_search = false si: question gÃ©nÃ©rale, salutation, demande de conseil sans critÃ¨res

QUALIFICATION CLIENT:
- cold: Premier contact, pas de critÃ¨res prÃ©cis
- warm: CritÃ¨res partiels, besoin de qualification 
- hot: CritÃ¨res complets, prÃªt Ã  voir des biens
- ready_to_visit: Exprime un intÃ©rÃªt pour visiter

STRATÃ‰GIES:
- search_and_present: Lancer recherche et prÃ©senter les biens
- qualify_more: Poser des questions pour affiner
- provide_consultation: Donner des conseils d'expert
- book_visit: Proposer une visite/rendez-vous

JSON uniquement, pas d'explication:"""

        try:
            start_time = time.time()
            
            response = self.client.messages.create(
                model=self.model,
                max_tokens=600,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )
            
            end_time = time.time()
            
            # Tracking des tokens
            usage = response.usage
            cost = token_tracker.calculate_cost(self.model, usage.input_tokens, usage.output_tokens)
            
            token_usage = TokenUsage(
                prompt_tokens=usage.input_tokens,
                completion_tokens=usage.output_tokens,
                total_tokens=usage.input_tokens + usage.output_tokens,
                cost_estimate=cost,
                model=self.model,
                timestamp=datetime.now(),
                usage_type="intent_analysis"
            )
            
            token_tracker.log_usage(token_usage)
            
            logger.info(f"ðŸ§  Claude intent analysis time: {(end_time - start_time):.2f}s")
            
            # Parse de la rÃ©ponse
            response_text = response.content[0].text.strip()
            
            # Nettoyage du JSON
            if response_text.startswith('```json'):
                response_text = response_text[7:-3]
            elif response_text.startswith('```'):
                response_text = response_text[3:-3]
            
            try:
                intent_analysis = json.loads(response_text)
                logger.info(f"ðŸ§  ANALYSE D'INTENT CLAUDE: {intent_analysis}")
                return intent_analysis
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Erreur parsing intent JSON: {str(e)}")
                # Fallback basique
                return {
                    "should_search": True,
                    "search_urgency": "immediate",
                    "client_qualification_level": "warm",
                    "detected_criteria": {"has_location": False, "has_budget": False, "has_property_type": False},
                    "conversation_strategy": "search_and_present",
                    "next_qualifying_questions": [],
                    "commercial_intent": "information_seeking"
                }
                
        except Exception as e:
            logger.error(f"âŒ Erreur Claude intent analysis: {str(e)}")
            # Fallback basique
            return {
                "should_search": True,
                "search_urgency": "immediate", 
                "client_qualification_level": "warm",
                "detected_criteria": {"has_location": False, "has_budget": False, "has_property_type": False},
                "conversation_strategy": "search_and_present",
                "next_qualifying_questions": [],
                "commercial_intent": "information_seeking"
            }

# --- SYSTÃˆME DE GESTION DE CONVERSATION AVANCÃ‰ ---
class AdvancedConversationManager:
    """Gestionnaire de conversation ultra-intelligent avec qualification client"""
    
    def __init__(self):
        self.client = anthropic_client
        self.model = CLAUDE_MODEL
        self.conversations = {}  # session_id -> conversation_history
        self.client_profiles = {}  # session_id -> profil client
    
    def get_or_create_conversation(self, session_id: str) -> List[Dict]:
        """RÃ©cupÃ¨re ou crÃ©e une nouvelle conversation"""
        if session_id not in self.conversations:
            self.conversations[session_id] = []
        return self.conversations[session_id]
    
    def get_or_create_client_profile(self, session_id: str) -> Dict:
        """RÃ©cupÃ¨re ou crÃ©e un profil client"""
        if session_id not in self.client_profiles:
            self.client_profiles[session_id] = {
                "qualification_level": "cold",
                "budget_range": None,
                "preferred_locations": [],
                "property_type": None,
                "timeline": None,
                "contact_info": {},
                "visit_interest": False,
                "interaction_count": 0
            }
        return self.client_profiles[session_id]
    
    def update_client_profile(self, session_id: str, intent_analysis: Dict, search_results: Dict = None):
        """Met Ã  jour le profil client basÃ© sur l'analyse d'intent"""
        profile = self.get_or_create_client_profile(session_id)
        
        # Mise Ã  jour du niveau de qualification
        profile["qualification_level"] = intent_analysis.get("client_qualification_level", "cold")
        profile["interaction_count"] += 1
        
        # Extraction des critÃ¨res dÃ©tectÃ©s
        if search_results and search_results.get("criteria"):
            criteria = search_results["criteria"]
            
            if criteria.get("price_min") or criteria.get("price_max"):
                profile["budget_range"] = {
                    "min": criteria.get("price_min"),
                    "max": criteria.get("price_max")
                }
            
            if criteria.get("locations"):
                profile["preferred_locations"].extend(criteria["locations"])
                profile["preferred_locations"] = list(set(profile["preferred_locations"]))  # Unique
            
            if criteria.get("property_type"):
                profile["property_type"] = criteria["property_type"]
        
        # DÃ©tecter l'intÃ©rÃªt pour une visite
        if intent_analysis.get("conversation_strategy") == "book_visit":
            profile["visit_interest"] = True
        
        logger.info(f"ðŸ‘¤ PROFIL CLIENT MIS Ã€ JOUR: {profile}")
    
    def add_message(self, session_id: str, role: str, content: str):
        """Ajoute un message Ã  la conversation"""
        conversation = self.get_or_create_conversation(session_id)
        conversation.append({"role": role, "content": content})
        
        # Garder seulement les 15 derniers messages
        if len(conversation) > 15:
            self.conversations[session_id] = conversation[-15:]
    
    async def generate_intelligent_response(self, session_id: str, user_message: str, intent_analysis: Dict, search_results: Optional[Dict] = None) -> str:
        """GÃ©nÃ¨re une rÃ©ponse ultra-intelligente basÃ©e sur l'analyse d'intent"""
        
        # Mettre Ã  jour le profil client
        self.update_client_profile(session_id, intent_analysis, search_results)
        
        # Ajouter le message utilisateur
        self.add_message(session_id, "user", user_message)
        conversation = self.get_or_create_conversation(session_id)
        client_profile = self.get_or_create_client_profile(session_id)
        
        # Construire le prompt systÃ¨me intelligent
        system_prompt = f"""Tu es Youssef, expert immobilier depuis 15 ans au Maroc. Ton objectif: qualifier le client et booker des visites.

PROFIL CLIENT ACTUEL:
- Niveau de qualification: {client_profile['qualification_level']}
- Interactions: {client_profile['interaction_count']}
- Budget: {client_profile['budget_range'] or 'Non dÃ©fini'}
- Zones d'intÃ©rÃªt: {', '.join(client_profile['preferred_locations']) or 'Aucune'}
- Type recherchÃ©: {client_profile['property_type'] or 'Non dÃ©fini'}
- IntÃ©rÃªt visite: {client_profile['visit_interest']}

ANALYSE D'INTENT ACTUELLE:
- StratÃ©gie recommandÃ©e: {intent_analysis.get('conversation_strategy')}
- Niveau qualification: {intent_analysis.get('client_qualification_level')}
- Intent commercial: {intent_analysis.get('commercial_intent')}
- Questions suggÃ©rÃ©es: {intent_analysis.get('next_qualifying_questions', [])}

DIRECTIVES COMMERCIALES:
1. Si stratÃ©gie = "search_and_present": PrÃ©sente les biens de maniÃ¨re engageante
2. Si stratÃ©gie = "qualify_more": Pose des questions intelligentes pour qualifier
3. Si stratÃ©gie = "provide_consultation": Donne des conseils d'expert 
4. Si stratÃ©gie = "book_visit": Propose activement une visite/rendez-vous

OBJECTIFS SELON QUALIFICATION:
- Cold (nouveau): Ã‰tablir confiance, comprendre besoins
- Warm (intÃ©ressÃ©): PrÃ©senter options, affiner critÃ¨res
- Hot (prÃªt): Proposer les meilleures options, pousser vers visite
- Ready_to_visit: Booker immÃ©diatement une visite

RÃˆGLES ABSOLUES:
- Pas d'emojis, langage naturel et professionnel
- Toujours dans la langue du client
- PrÃ©sente les rÃ©sultats comme ton portefeuille personnel
- Pose 1-2 questions stratÃ©giques pour avancer la vente
- Si client qualifiÃ©, propose TOUJOURS une visite

STYLE: Expert confiant, commercial mais pas agressif, axÃ© rÃ©sultats."""

        # Ajouter les rÃ©sultats de recherche si disponibles
        if search_results and search_results.get("results"):
            properties_context = f"\n\nRÃ‰SULTATS DE RECHERCHE DISPONIBLES:\n"
            properties_context += f"Tu as {search_results.get('total_results', 0)} propriÃ©tÃ©s dans ton portefeuille qui correspondent.\n\n"
            
            if len(search_results["results"]) > 0:
                properties_context += "PROPRIÃ‰TÃ‰S Ã€ PRÃ‰SENTER (choisir les meilleures selon le profil client):\n"
                for i, prop in enumerate(search_results["results"][:8], 1):
                    properties_context += f"\nOption {i}: {prop.get('property_type', 'PropriÃ©tÃ©')} Ã  {prop.get('city', 'N/A')}\n"
                    properties_context += f"   Prix: {prop.get('price', 'Ã€ nÃ©gocier')} DH\n"
                    properties_context += f"   Superficie: {prop.get('area', 'N/A')} mÂ²\n"
                    properties_context += f"   Quartier: {prop.get('neighborhood', 'N/A')}\n"
                    properties_context += f"   Chambres: {prop.get('bedrooms', 'N/A')}\n"
                    properties_context += f"   Score: {prop.get('score', 0):.1f}/10\n"
                
                properties_context += f"\nSTRATÃ‰GIE: PrÃ©sente 2-3 meilleures options selon le profil, crÃ©e l'urgence, propose visite."
            
            system_prompt += properties_context
        
        try:
            start_time = time.time()
            
            # PrÃ©parer les messages pour Claude
            messages = []
            for msg in conversation:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            
            # Appel Ã  Claude 4 Sonnet avec prompt intelligent
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1200,
                temperature=0.7,
                system=system_prompt,
                messages=messages
            )
            
            end_time = time.time()
            
            # Tracking des tokens
            usage = response.usage
            cost = token_tracker.calculate_cost(self.model, usage.input_tokens, usage.output_tokens)
            
            token_usage = TokenUsage(
                prompt_tokens=usage.input_tokens,
                completion_tokens=usage.output_tokens,
                total_tokens=usage.input_tokens + usage.output_tokens,
                cost_estimate=cost,
                model=self.model,
                timestamp=datetime.now(),
                usage_type="conversation"
            )
            
            token_tracker.log_usage(token_usage)
            
            logger.info(f"ðŸ’¬ Claude response time: {(end_time - start_time):.2f}s")
            
            # Extraire la rÃ©ponse
            assistant_response = response.content[0].text
            
            # Ajouter la rÃ©ponse Ã  la conversation
            self.add_message(session_id, "assistant", assistant_response)
            
            return assistant_response
            
        except Exception as e:
            logger.error(f"âŒ Erreur Claude conversation: {str(e)}")
            return "DÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me technique. Pouvez-vous reformuler votre demande ?"

# --- ANALYSEUR DE REQUÃŠTE OPTIMISÃ‰ (CONSERVÃ‰) ---
class OptimizedQueryAnalyzer:
    """Analyseur hybride : rÃ¨gles + LLM en fallback"""
    
    # Patterns prÃ©-compilÃ©s pour performance
    PRICE_PATTERNS = [
        re.compile(r'entre\s+(\d+(?:\s*000)*)\s*(?:et|Ã |-)\s*(\d+(?:\s*000)*)', re.IGNORECASE),
        re.compile(r'de\s+(\d+(?:\s*000)*)\s*(?:Ã |-)\s*(\d+(?:\s*000)*)', re.IGNORECASE),
        re.compile(r'budget\s+(\d+(?:\s*000)*)\s*(?:Ã |-)\s*(\d+(?:\s*000)*)', re.IGNORECASE),
        re.compile(r'maximum\s+(\d+(?:\s*000)*)', re.IGNORECASE),
        re.compile(r'max\s+(\d+(?:\s*000)*)', re.IGNORECASE),
        re.compile(r'moins\s+de\s+(\d+(?:\s*000)*)', re.IGNORECASE),
        re.compile(r'(\d+)\s*millions?', re.IGNORECASE),
        re.compile(r'(\d+),(\d+)\s*millions?', re.IGNORECASE),
    ]
    
    AREA_PATTERNS = [
        re.compile(r'(\d+)\s*(?:Ã |-)\s*(\d+)\s*m[Â²2]', re.IGNORECASE),
        re.compile(r'entre\s+(\d+)\s*(?:et|Ã |-)\s*(\d+)\s*m[Â²2]', re.IGNORECASE),
        re.compile(r'minimum\s+(\d+)\s*m[Â²2]', re.IGNORECASE),
    ]
    
    BEDROOM_PATTERNS = [
        re.compile(r'(\d+)\s*chambres?', re.IGNORECASE),
        re.compile(r'(\d+)\s*ch\b', re.IGNORECASE),
    ]
    
    ROOM_PATTERNS = [
        re.compile(r'(\d+)\s*piÃ¨ces?', re.IGNORECASE),
        re.compile(r'(\d+)p\b', re.IGNORECASE),
    ]
    
    KNOWN_LOCATIONS = {
        'casablanca', 'casa', 'rabat', 'marrakech', 'fes', 'tanger',
        'agdal', 'hay riad', 'souissi', 'centre ville', 'maarif',
        'ain diab', 'bourgogne', 'palmier', 'val fleuri'
    }
    
    PROPERTY_TYPES = {
        'appartement', 'villa', 'maison', 'studio', 'duplex', 'triplex'
    }
    
    AMENITIES = {
        'piscine', 'garage', 'terrasse', 'jardin', 'ascenseur', 'parking'
    }
    
    @classmethod
    def extract_with_rules(cls, query: str) -> Dict[str, Any]:
        """Extraction basÃ©e sur des rÃ¨gles (rapide, 0 token)"""
        text_lower = query.lower()
        criteria = {
            "price_min": None, "price_max": None,
            "area_min": None, "area_max": None,
            "bedrooms_min": None, "rooms_min": None,
            "locations": [], "property_type": None, "search_terms": []
        }
        
        # Prix
        for pattern in cls.PRICE_PATTERNS:
            match = pattern.search(text_lower)
            if match:
                if pattern.pattern == r'(\d+)\s*millions?':
                    millions = int(match.group(1))
                    criteria["price_max"] = millions * 1000000
                elif pattern.pattern == r'(\d+),(\d+)\s*millions?':
                    millions = float(match.group(1) + '.' + match.group(2))
                    criteria["price_max"] = int(millions * 1000000)
                elif len(match.groups()) == 2:
                    criteria["price_min"] = int(match.group(1).replace(' ', ''))
                    criteria["price_max"] = int(match.group(2).replace(' ', ''))
                elif len(match.groups()) == 1:
                    criteria["price_max"] = int(match.group(1).replace(' ', ''))
                break
        
        # Superficie
        for pattern in cls.AREA_PATTERNS:
            match = pattern.search(text_lower)
            if match:
                if len(match.groups()) == 2:
                    criteria["area_min"] = int(match.group(1))
                    criteria["area_max"] = int(match.group(2))
                elif len(match.groups()) == 1:
                    criteria["area_min"] = int(match.group(1))
                break
        
        # Chambres
        for pattern in cls.BEDROOM_PATTERNS:
            match = pattern.search(text_lower)
            if match:
                criteria["bedrooms_min"] = int(match.group(1))
                break
        
        # PiÃ¨ces
        for pattern in cls.ROOM_PATTERNS:
            match = pattern.search(text_lower)
            if match:
                criteria["rooms_min"] = int(match.group(1))
                break
        
        # Locations
        for location in cls.KNOWN_LOCATIONS:
            if location in text_lower:
                criteria["locations"].append(location)
        
        # Type de propriÃ©tÃ©
        for prop_type in cls.PROPERTY_TYPES:
            if prop_type in text_lower:
                criteria["property_type"] = prop_type
                break
        
        # Amenities
        for amenity in cls.AMENITIES:
            if amenity in text_lower:
                criteria["search_terms"].append(amenity)
        
        return criteria

# --- LLM GROQ LLAMA3 AVEC TRACKING (CONSERVÃ‰) ---
class GroqLlama3Extractor:
    """Extracteur utilisant Groq Llama3 avec tracking des tokens"""
    
    def __init__(self):
        self.client = groq_client
        self.model = GROQ_MODEL
    
    def extract_criteria(self, query: str) -> Dict[str, Any]:
        """Extraction avec Groq Llama3 et tracking des tokens"""
        
        prompt = f"""Analyse cette requÃªte de recherche immobiliÃ¨re et extrait UNIQUEMENT les critÃ¨res spÃ©cifiques mentionnÃ©s.
RequÃªte: "{query}"

RÃ©ponds SEULEMENT avec un JSON valide dans ce format exact:
{{
    "price_min": null,
    "price_max": null,
    "area_min": null,
    "area_max": null,
    "bedrooms_min": null,
    "rooms_min": null,
    "locations": [],
    "property_type": null,
    "search_terms": []
}}

RÃ¨gles importantes:
- Si un budget/prix est mentionnÃ©, extrait price_min et/ou price_max
- Si une superficie est mentionnÃ©e, extrait area_min et/ou area_max  
- Si nombre de chambres mentionnÃ©, extrait bedrooms_min
- Si nombre de piÃ¨ces mentionnÃ©, extrait rooms_min
- locations: quartiers/villes mentionnÃ©s
- property_type: appartement, villa, maison, studio, etc.
- search_terms: mots-clÃ©s descriptifs (piscine, garage, terrasse, etc.)
- Si on mentionne "X millions" ou "X millions de dirhams/dh", convertis en nombre (ex: 3 millions = 3000000)

N'invente aucune valeur. Si non mentionnÃ© = null ou []

JSON:"""
        
        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=500,
                top_p=0.9
            )
            
            end_time = time.time()
            
            # Tracking des tokens
            usage = response.usage
            cost = token_tracker.calculate_cost(self.model, usage.prompt_tokens, usage.completion_tokens)
            
            token_usage = TokenUsage(
                prompt_tokens=usage.prompt_tokens,
                completion_tokens=usage.completion_tokens,
                total_tokens=usage.total_tokens,
                cost_estimate=cost,
                model=self.model,
                timestamp=datetime.now(),
                usage_type="search"
            )
            
            token_tracker.log_usage(token_usage)
            
            logger.info(f"âš¡ Groq response time: {(end_time - start_time):.2f}s")
            
            response_text = response.choices[0].message.content.strip()
            
            if response_text.startswith('```json'):
                response_text = response_text[7:-3]
            elif response_text.startswith('```'):
                response_text = response_text[3:-3]
            
            try:
                criteria = json.loads(response_text)
                return criteria
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Erreur de parsing JSON: {str(e)}")
                return OptimizedQueryAnalyzer.extract_with_rules(query)
            
        except Exception as e:
            logger.error(f"âŒ Erreur Groq Llama3: {str(e)}")
            return OptimizedQueryAnalyzer.extract_with_rules(query)

# --- SYSTÃˆME DE CACHE SIMPLE (CONSERVÃ‰) ---
class SimpleCache:
    """Cache en mÃ©moire simple pour Ã©viter les appels rÃ©pÃ©tÃ©s"""
    
    def __init__(self, max_size: int = 1000):
        self.cache: Dict[str, tuple] = {}
        self.max_size = max_size
    
    def _normalize_query(self, query: str) -> str:
        return re.sub(r'\s+', ' ', query.lower().strip())
    
    def get(self, query: str) -> Optional[Dict]:
        key = self._normalize_query(query)
        if key in self.cache:
            result, timestamp = self.cache[key]
            if datetime.now() - timestamp < timedelta(hours=1):
                logger.info(f"ðŸŽ¯ Cache HIT pour: {query[:50]}...")
                return result
            else:
                del self.cache[key]
        return None
    
    def set(self, query: str, result: Dict):
        key = self._normalize_query(query)
        
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k][1])
            del self.cache[oldest_key]
        
        self.cache[key] = (result, datetime.now())
        logger.info(f"ðŸ’¾ Cache MISS - SauvegardÃ©: {query[:50]}...")

# --- ELASTICSEARCH QUERY BUILDER (CONSERVÃ‰) ---
class ElasticsearchQueryBuilder:
    """Construit des requÃªtes Elasticsearch optimisÃ©es"""
    
    @staticmethod
    def build_query(criteria: Dict[str, Any], search_terms: str = "") -> Dict[str, Any]:
        query = {
            "bool": {
                "must": [],
                "filter": [],
            }
        }

        # Filtres numÃ©riques exacts
        if criteria.get("price_min") or criteria.get("price_max"):
            price_filter = {"range": {"price": {}}}
            if criteria.get("price_min"):
                price_filter["range"]["price"]["gte"] = criteria["price_min"]
            if criteria.get("price_max"):
                price_filter["range"]["price"]["lte"] = criteria["price_max"]
            query["bool"]["filter"].append(price_filter)

        if criteria.get("area_min") or criteria.get("area_max"):
            area_filter = {"range": {"area": {}}}
            if criteria.get("area_min"):
                area_filter["range"]["area"]["gte"] = criteria["area_min"]
            if criteria.get("area_max"):
                area_filter["range"]["area"]["lte"] = criteria["area_max"]
            query["bool"]["filter"].append(area_filter)

        if criteria.get("bedrooms_min"):
            query["bool"]["filter"].append({
                "range": {"bedrooms": {"gte": criteria["bedrooms_min"]}}
            })

        if criteria.get("rooms_min"):
            query["bool"]["filter"].append({
                "range": {"rooms": {"gte": criteria["rooms_min"]}}
            })

        # Localisations
        if criteria.get("locations"):
            for location in criteria["locations"]:
                query["bool"]["must"].append({
                    "multi_match": {
                        "query": location,
                        "fields": ["city^2", "neighborhood^2"],
                        "fuzziness": "AUTO"
                    }
                })

        # Type de propriÃ©tÃ©
        if criteria.get("property_type"):
            query["bool"]["must"].append({
                "match": {"property_type": {"query": criteria["property_type"], "boost": 2}}
            })

        # search_terms
        if criteria.get("search_terms"):
            for term in criteria["search_terms"]:
                query["bool"]["must"].append({
                    "multi_match": {
                        "query": term,
                        "fields": ["description^1.5", "features^1.2", "extras^1.1"],
                        "fuzziness": "AUTO"
                    }
                })

        # Recherche textuelle gÃ©nÃ©rale (fallback)
        if not (criteria.get("locations") or criteria.get("property_type") or criteria.get("search_terms")) and search_terms:
            query["bool"]["must"].append({
                "multi_match": {
                    "query": search_terms,
                    "fields": ["full_text^1", "description^1.2", "features^1.1"],
                    "fuzziness": "AUTO"
                }
            })

        # Si aucun must, on fait un match_all
        if not query["bool"]["must"]:
            query["bool"]["must"].append({"match_all": {}})

        return {
            "query": query,
            "sort": [
                {"_score": {"order": "desc"}},
                {"price": {"order": "asc"}}
            ],
            "size": 20
        }

# Instances globales - ORDRE IMPORTANT !
cache = SimpleCache()
groq_extractor = GroqLlama3Extractor()

# CrÃ©er les instances des nouvelles classes
conversation_manager = AdvancedConversationManager()
intent_analyzer = IntelligentIntentAnalyzer()

# --- FONCTION DE RECHERCHE OPTIMISÃ‰E (CONSERVÃ‰E) ---
def search_properties(query: str) -> Dict[str, Any]:
    """Recherche optimisÃ©e avec extraction Llama3 et tracking des tokens - VERSION DEBUG"""
    try:
        logger.info("ðŸš€ðŸš€ðŸš€ DÃ‰BUT FONCTION SEARCH_PROPERTIES ðŸš€ðŸš€ðŸš€")
        logger.info(f"ðŸ“ RequÃªte reÃ§ue: '{query}'")
        
        # 1. VÃ©rifier le cache
        logger.info("ðŸ’¾ VÃ©rification du cache...")
        cached_result = cache.get(query)
        if cached_result:
            logger.info(f"ðŸŽ¯ CACHE HIT - RequÃªte servie depuis le cache")
            cached_result["extraction_method"] = "GROQ_LLAMA3"
            return cached_result
        
        logger.info("ðŸ’¾ CACHE MISS - ProcÃ©dure complÃ¨te")
        
        # 2. Extraction via Llama3 avec tracking des tokens
        logger.info("ðŸ¤– === DÃ‰BUT EXTRACTION GROQ LLAMA3 ===")
        criteria = groq_extractor.extract_criteria(query)
        extraction_method = "GROQ_LLAMA3"
        logger.info("ðŸ¤– === FIN EXTRACTION GROQ LLAMA3 ===")
        
        logger.info(f"ðŸ“‹ CritÃ¨res extraits ({extraction_method}): {criteria}")
        
        # 3. Construction de la requÃªte Elasticsearch
        logger.info("ðŸ”§ Construction de la requÃªte Elasticsearch...")
        es_query = ElasticsearchQueryBuilder.build_query(criteria, query)
        logger.info(f"ðŸ”§ RequÃªte ES construite: {json.dumps(es_query, indent=2)}")
        
        # 4. ExÃ©cution de la recherche
        logger.info("ðŸ” === DÃ‰BUT RECHERCHE ELASTICSEARCH ===")
        logger.info(f"ðŸ” Index: {ES_INDEX}")
        logger.info(f"ðŸ” Query: {es_query}")
        
        res = es.search(index=ES_INDEX, body=es_query)
        logger.info("ðŸ” === RECHERCHE ELASTICSEARCH TERMINÃ‰E ===")
        
        hits = res["hits"]["hits"]
        total = res["hits"]["total"]["value"] if isinstance(res["hits"]["total"], dict) else res["hits"]["total"]
        
        logger.info(f"ðŸ“Š RÃ©sultats bruts ES: {len(hits)} hits, total: {total}")
        
        # 5. Formatage des rÃ©sultats
        logger.info("ðŸŽ¨ Formatage des rÃ©sultats...")
        results = []
        for i, hit in enumerate(hits):
            result = hit["_source"].copy()
            result["score"] = hit["_score"]
            
            if result.get("price") and result.get("area") and result["area"] > 0:
                result["price_per_sqm"] = round(result["price"] / result["area"], 2)
            
            results.append(result)
            logger.info(f"ðŸ“‹ RÃ©sultat {i+1}: {result.get('city', 'N/A')} - {result.get('property_type', 'N/A')} - {result.get('price', 'N/A')}DH")
        
        # 6. Log des rÃ©sultats dÃ©taillÃ©s
        logger.info(f"âœ… === RÃ‰SULTATS FINAUX ===")
        logger.info(f"âœ… {len(results)} rÃ©sultats formatÃ©s sur {total} total")
        for i, r in enumerate(results[:3], 1):  # Log des 3 premiers
            logger.info(f"ðŸ  TOP {i}: {r.get('city', 'N/A')} - {r.get('neighborhood', 'N/A')} - "
                       f"{r.get('price', 'N/A')}DH - {r.get('area', 'N/A')}mÂ² - Score: {r['score']:.2f}")
        
        # 7. PrÃ©parer le rÃ©sultat final
        final_result = {
            "query": query,
            "criteria": criteria,
            "extraction_method": extraction_method,
            "total_results": total,
            "results": results
        }
        
        logger.info(f"âœ… RÃ©sultat final prÃ©parÃ©: {len(results)} propriÃ©tÃ©s")
        
        # 8. Sauvegarder en cache
        cache.set(query, final_result)
        logger.info("ðŸ’¾ RÃ©sultat sauvegardÃ© en cache")
        
        logger.info("ðŸš€ðŸš€ðŸš€ FIN FONCTION SEARCH_PROPERTIES - SUCCÃˆS ðŸš€ðŸš€ðŸš€")
        return final_result
        
    except Exception as e:
        logger.error(f"âŒâŒâŒ ERREUR DANS SEARCH_PROPERTIES âŒâŒâŒ")
        logger.error(f"âŒ Type erreur: {type(e).__name__}")
        logger.error(f"âŒ Message: {str(e)}")
        logger.error(f"âŒ Traceback complet:", exc_info=True)
        
        return {
            "query": query,
            "criteria": {},
            "extraction_method": "GROQ_LLAMA3",  # MÃªme en cas d'erreur
            "total_results": 0,
            "results": [],
            "error": str(e)
        }

# --- ORCHESTRATEUR PRINCIPAL ULTRA-INTELLIGENT ---
class UltraIntelligentOrchestrator:
    """Orchestrateur principal avec IA hybride Claude + Groq pour une expÃ©rience optimale"""
    
    def __init__(self):
        # Utiliser les instances globales
        self.conversation_manager = conversation_manager
        self.intent_analyzer = intent_analyzer
    
    async def process_message_intelligently(self, session_id: str, user_message: str) -> Dict[str, Any]:
        """Traite un message avec une intelligence artificielle hybride ultra-avancÃ©e"""
        
        logger.info("ðŸ§ ðŸ§ ðŸ§  DÃ‰BUT PROCESSUS INTELLIGENCE HYBRIDE ðŸ§ ðŸ§ ðŸ§ ")
        logger.info(f"ðŸ§  Session: {session_id}")
        logger.info(f"ðŸ§  Message: '{user_message}'")
        
        # Ã‰TAPE 1: ANALYSE D'INTENT INTELLIGENTE AVEC CLAUDE
        logger.info("ðŸŽ¯ === Ã‰TAPE 1: ANALYSE D'INTENT CLAUDE ===")
        conversation_history = self.conversation_manager.get_or_create_conversation(session_id)
        
        try:
            intent_analysis = await self.intent_analyzer.analyze_intent_and_decide(
                user_message=user_message,
                conversation_history=conversation_history
            )
            logger.info(f"ðŸŽ¯ INTENT ANALYSÃ‰: {intent_analysis}")
        except Exception as e:
            logger.error(f"âŒ Erreur analyse intent: {str(e)}")
            # Fallback
            intent_analysis = {
                "should_search": True,
                "search_urgency": "immediate",
                "client_qualification_level": "warm",
                "conversation_strategy": "search_and_present"
            }
        
        # Ã‰TAPE 2: DÃ‰CISION DE RECHERCHE BASÃ‰E SUR L'INTELLIGENCE CLAUDE
        search_results = None
        should_search = intent_analysis.get("should_search", False)
        search_urgency = intent_analysis.get("search_urgency", "none")
        
        if should_search and search_urgency in ["immediate", "progressive"]:
            logger.info("ðŸ” === Ã‰TAPE 2: RECHERCHE GROQ + ELASTICSEARCH ===")
            logger.info(f"ðŸ” Urgence: {search_urgency}")
            logger.info(f"ðŸ” Niveau client: {intent_analysis.get('client_qualification_level')}")
            
            try:
                search_results = search_properties(user_message)
                logger.info(f"âœ… RECHERCHE TERMINÃ‰E: {search_results.get('total_results', 0)} rÃ©sultats")
                logger.info(f"ðŸ“‹ CritÃ¨res Groq: {search_results.get('criteria', {})}")
            except Exception as e:
                logger.error(f"âŒ Erreur recherche: {str(e)}")
        else:
            logger.info("ðŸ’¬ === CONVERSATION PURE - PAS DE RECHERCHE ===")
            logger.info(f"ðŸ’¬ Raison: should_search={should_search}, urgency={search_urgency}")
        
        # Ã‰TAPE 3: GÃ‰NÃ‰RATION DE RÃ‰PONSE INTELLIGENTE AVEC CLAUDE
        logger.info("ðŸ¤– === Ã‰TAPE 3: GÃ‰NÃ‰RATION RÃ‰PONSE INTELLIGENTE ===")
        
        try:
            conversational_response = await self.conversation_manager.generate_intelligent_response(
                session_id=session_id,
                user_message=user_message,
                intent_analysis=intent_analysis,
                search_results=search_results
            )
            logger.info("ðŸ¤– RÃ‰PONSE GÃ‰NÃ‰RÃ‰E AVEC SUCCÃˆS")
        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration rÃ©ponse: {str(e)}")
            conversational_response = "DÃ©solÃ©, j'ai rencontrÃ© un problÃ¨me technique."
        
        # Ã‰TAPE 4: PRÃ‰PARATION RÃ‰PONSE FINALE AVEC MÃ‰TADONNÃ‰ES
        logger.info("ðŸ“¦ === Ã‰TAPE 4: PRÃ‰PARATION RÃ‰PONSE FINALE ===")
        
        # RÃ©cupÃ©rer le profil client mis Ã  jour
        client_profile = self.conversation_manager.get_or_create_client_profile(session_id)
        
        response = {
            "message": conversational_response,
            "sender": "bot",
            "timestamp": datetime.now().isoformat(),
            "session_id": session_id,
            
            # MÃ©tadonnÃ©es d'intelligence
            "intent_analysis": intent_analysis,
            "client_profile": client_profile,
            "had_search": should_search,
            "search_urgency": search_urgency,
            
            # MÃ©triques commerciales
            "qualification_level": intent_analysis.get("client_qualification_level"),
            "commercial_intent": intent_analysis.get("commercial_intent"),
            "next_action_suggested": intent_analysis.get("conversation_strategy"),
            "ready_for_visit": client_profile.get("visit_interest", False)
        }
        
        # Ajouter les rÃ©sultats de recherche si disponibles
        if search_results and search_results.get("results"):
            top_results = search_results["results"][:3]
            other_results = search_results["results"][3:]
            
            response.update({
                "properties": top_results,
                "otherProperties": other_results,
                "totalResults": search_results["total_results"],
                "criteria": search_results["criteria"],
                "extractionMethod": search_results["extraction_method"]
            })
            
            logger.info(f"ðŸ“Š PROPRIÃ‰TÃ‰S AJOUTÃ‰ES: {len(top_results)} top + {len(other_results)} autres")
        
        # Log final du niveau de qualification
        if client_profile["qualification_level"] in ["hot", "ready_to_visit"]:
            logger.info(f"ðŸ”¥ CLIENT QUALIFIÃ‰: {client_profile['qualification_level']} - PRÃŠT POUR VISITE!")
        
        logger.info("ðŸ§ ðŸ§ ðŸ§  FIN PROCESSUS INTELLIGENCE HYBRIDE - SUCCÃˆS ðŸ§ ðŸ§ ðŸ§ ")
        return response

# --- API FASTAPI ---
class QueryRequest(BaseModel):
    user_query: str
    session_id: Optional[str] = None

class MessageRequest(BaseModel):
    message: str
    sender: str
    session_id: Optional[str] = None

class WebSocketManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: Dict):
        for connection in self.active_connections:
            await connection.send_json(message)

app = FastAPI(title="Chatbot Immobilier Ultra-Intelligent", version="4.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Instances globales des managers
manager = WebSocketManager()
orchestrator = UltraIntelligentOrchestrator()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    session_id = str(uuid.uuid4())  # GÃ©nÃ©rer un session_id unique pour cette connexion
    logger.info(f"ðŸ”Œ Nouvelle connexion WebSocket avec session: {session_id}")
    
    try:
        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            if message_data.get("sender") == "user":
                user_message = message_data.get("message", "")
                
                # Envoi d'un message "en train de traiter..."
                await websocket.send_json({
                    "message": "Youssef analyse votre demande...",
                    "sender": "bot",
                    "timestamp": datetime.now().isoformat(),
                    "session_id": session_id,
                    "is_typing": True
                })
                
                # Traitement avec l'orchestrateur intelligent
                response = await orchestrator.process_message_intelligently(session_id, user_message)
                
                # Envoi de la rÃ©ponse finale
                await websocket.send_json(response)
            
    except WebSocketDisconnect:
        manager.disconnect(websocket)
        logger.info(f"ðŸ”Œ DÃ©connexion WebSocket pour session: {session_id}")

@app.post("/chat")
async def chat_endpoint(request: MessageRequest):
    """Endpoint REST pour le chat conversationnel intelligent"""
    try:
        session_id = request.session_id or str(uuid.uuid4())
        response = await orchestrator.process_message_intelligently(session_id, request.message)
        return response
    except Exception as e:
        logger.error(f"âŒ Erreur lors du chat: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur de chat: {str(e)}")

@app.post("/search")
async def search_endpoint(request: QueryRequest):
    """Endpoint REST pour la recherche pure (legacy)"""
    try:
        results = search_properties(request.user_query)
        return results
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la recherche: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur de recherche: {str(e)}")

@app.get("/stats")
def get_advanced_stats():
    """Endpoint pour rÃ©cupÃ©rer les statistiques avancÃ©es avec intelligence et qualification"""
    
    # Stats quotidiennes avec breakdown par type
    daily_stats = {
        "queries": len(token_tracker.daily_usage),
        "tokens": sum(u.total_tokens for u in token_tracker.daily_usage),
        "cost": sum(u.cost_estimate for u in token_tracker.daily_usage),
        "search_tokens": sum(u.total_tokens for u in token_tracker.daily_usage if u.usage_type == "search"),
        "conversation_tokens": sum(u.total_tokens for u in token_tracker.daily_usage if u.usage_type == "conversation"),
        "intent_analysis_tokens": sum(u.total_tokens for u in token_tracker.daily_usage if u.usage_type == "intent_analysis"),
    }
    
    # Stats des clients par niveau de qualification
    all_profiles = conversation_manager.client_profiles
    qualification_stats = {
        "cold": len([p for p in all_profiles.values() if p["qualification_level"] == "cold"]),
        "warm": len([p for p in all_profiles.values() if p["qualification_level"] == "warm"]),
        "hot": len([p for p in all_profiles.values() if p["qualification_level"] == "hot"]),
        "ready_to_visit": len([p for p in all_profiles.values() if p["qualification_level"] == "ready_to_visit"]),
        "total_qualified": len([p for p in all_profiles.values() if p["qualification_level"] in ["hot", "ready_to_visit"]]),
        "visit_interest": len([p for p in all_profiles.values() if p["visit_interest"] == True])
    }
    
    # Historique des requÃªtes avec mÃ©tadonnÃ©es d'intelligence
    recent_requests = []
    for i, usage in enumerate(token_tracker.daily_usage[-15:]):
        recent_requests.append({
            "id": i+1,
            "timestamp": usage.timestamp.strftime('%H:%M:%S'),
            "model": usage.model,
            "usage_type": usage.usage_type,
            "prompt_tokens": usage.prompt_tokens,
            "completion_tokens": usage.completion_tokens,
            "total_tokens": usage.total_tokens,
            "cost": usage.cost_estimate
        })
    
    # Performance de l'IA
    ai_performance = {
        "total_sessions": len(conversation_manager.conversations),
        "avg_messages_per_session": sum(len(conv) for conv in conversation_manager.conversations.values()) / max(len(conversation_manager.conversations), 1),
        "qualified_conversion_rate": (qualification_stats["total_qualified"] / max(len(all_profiles), 1)) * 100,
        "visit_conversion_rate": (qualification_stats["visit_interest"] / max(len(all_profiles), 1)) * 100
    }
    
    return {
        "daily_stats": daily_stats,
        "total_stats": token_tracker.total_usage,
        "qualification_stats": qualification_stats,
        "ai_performance": ai_performance,
        "cache_stats": {
            "cache_size": len(cache.cache),
            "max_cache_size": cache.max_size
        },
        "conversation_stats": {
            "active_sessions": len(conversation_manager.conversations),
            "total_messages": sum(len(conv) for conv in conversation_manager.conversations.values()),
            "active_websockets": len(manager.active_connections),
            "client_profiles": len(conversation_manager.client_profiles)
        },
        "recent_requests": recent_requests
    }

@app.get("/qualified-leads")
def get_qualified_leads():
    """Endpoint pour les agents commerciaux - Leads qualifiÃ©s prÃªts pour visite"""
    
    qualified_leads = []
    
    for session_id, profile in conversation_manager.client_profiles.items():
        if profile["qualification_level"] in ["hot", "ready_to_visit"] or profile["visit_interest"]:
            
            # RÃ©cupÃ©rer la derniÃ¨re conversation
            conversation = conversation_manager.conversations.get(session_id, [])
            last_messages = conversation[-3:] if conversation else []
            
            lead = {
                "session_id": session_id,
                "qualification_level": profile["qualification_level"],
                "visit_interest": profile["visit_interest"],
                "budget_range": profile["budget_range"],
                "preferred_locations": profile["preferred_locations"],
                "property_type": profile["property_type"],
                "interaction_count": profile["interaction_count"],
                "contact_info": profile["contact_info"],
                "last_messages": [
                    {
                        "role": msg["role"],
                        "content": msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
                    } for msg in last_messages
                ],
                "priority": "HIGH" if profile["qualification_level"] == "ready_to_visit" else "MEDIUM"
            }
            
            qualified_leads.append(lead)
    
    # Trier par prioritÃ© et niveau de qualification
    qualified_leads.sort(key=lambda x: (
        x["qualification_level"] == "ready_to_visit",
        x["visit_interest"],
        x["interaction_count"]
    ), reverse=True)
    
    return {
        "total_qualified_leads": len(qualified_leads),
        "high_priority": len([l for l in qualified_leads if l["priority"] == "HIGH"]),
        "leads": qualified_leads
    }

@app.get("/health")
def health_check():
    return {
        "status": "healthy", 
        "elasticsearch": es.ping(),
        "total_queries": token_tracker.total_usage['total_queries'],
        "total_tokens": token_tracker.total_usage['total_tokens'],
        "active_conversations": len(conversation_manager.conversations),
        "qualified_leads": len([p for p in conversation_manager.client_profiles.values() 
                               if p["qualification_level"] in ["hot", "ready_to_visit"]])
    }

# Route pour la page d'accueil
@app.get("/")
async def read_index():
    """Sert la page d'accueil"""
    from fastapi.responses import FileResponse
    return FileResponse('static/index.html')

# Monter les fichiers statiques sur un chemin spÃ©cifique pour Ã©viter les conflits
app.mount("/static", StaticFiles(directory="static"), name="static")

def log_es_index_structure():
    """Fonction pour logger la structure de l'index Elasticsearch"""
    try:
        logger.info("==== [ES] Mapping de l'index '%s' ====" % ES_INDEX)
        mapping = es.indices.get_mapping(index=ES_INDEX)
        # Affiche les champs du mapping
        props = mapping[ES_INDEX]['mappings'].get('properties', {})
        logger.info("Champs de l'index : %s", list(props.keys()))
        for field, desc in props.items():
            logger.info("  - %s: %s", field, desc.get('type', str(desc)))
    except Exception as e:
        logger.error("Erreur lors de la rÃ©cupÃ©ration du mapping: %s", str(e))
    try:
        logger.info("==== [ES] Exemples de documents dans '%s' ====" % ES_INDEX)
        res = es.search(index=ES_INDEX, body={"query": {"match_all": {}}, "size": 3})
        for i, hit in enumerate(res['hits']['hits'], 1):
            logger.info("Exemple %d: %s", i, json.dumps(hit['_source'], ensure_ascii=False))
    except Exception as e:
        logger.error("Erreur lors de la rÃ©cupÃ©ration des exemples: %s", str(e))

# Appel au dÃ©marrage
log_es_index_structure()

def initialize_system():
    """Initialise le systÃ¨me avec vÃ©rifications"""
    try:
        logger.info("ðŸ”§ === INITIALISATION DU SYSTÃˆME ===")
        
        # VÃ©rifier Elasticsearch
        if es.ping():
            logger.info("âœ… Elasticsearch connectÃ©")
        else:
            logger.error("âŒ Elasticsearch non disponible")
        
        # VÃ©rifier Groq
        try:
            test_criteria = groq_extractor.extract_criteria("test")
            logger.info("âœ… Groq Llama3 opÃ©rationnel")
        except Exception as e:
            logger.error(f"âŒ Groq Llama3 erreur: {str(e)}")
        
        # VÃ©rifier Claude
        if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != "votre_cle_anthropic_ici":
            logger.info("âœ… Claude 4 Sonnet configurÃ©")
        else:
            logger.error("âŒ ClÃ© Anthropic manquante - Configurez ANTHROPIC_API_KEY")
        
        logger.info("ðŸ”§ === SYSTÃˆME INITIALISÃ‰ ===")
        
    except Exception as e:
        logger.error(f"âŒ Erreur initialisation: {str(e)}")

# Initialiser le systÃ¨me
initialize_system()

if __name__ == "__main__":
    import uvicorn
    logger.info("ðŸš€ DÃ©marrage du chatbot conversationnel ultra-intelligent")
    logger.info("ðŸ§  Claude 4 Sonnet + Groq Llama3 + Intelligence Hybride")
    logger.info("ðŸŽ¯ SystÃ¨me de qualification client automatique")
    uvicorn.run(app, host="0.0.0.0", port=8000)
